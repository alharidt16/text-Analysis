{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1rxi_TCPEtH9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTt2a10SF-Bu",
    "outputId": "285b270f-e1e5-4383-c411-dc4eb575cc71"
   },
   "outputs": [],
   "source": [
    "#!pip install pyLDAvis==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "CqY9k9D5N6ia",
    "outputId": "0748220d-ca5e-4f68-85a3-0c1f7c24cec9"
   },
   "outputs": [],
   "source": [
    "#!pip install pandas==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "a_3wqP-XFHvd",
    "outputId": "b321b8dd-5d83-403f-dfca-bfda688e19da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>userName</th>\n",
       "      <th>contentp</th>\n",
       "      <th>contentp_clean</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-21 14:31:30</td>\n",
       "      <td>Sering muncul peringatan 'anda tidak terhubung...</td>\n",
       "      <td>5</td>\n",
       "      <td>Wilson Nts</td>\n",
       "      <td>sering muncul peringatan anda tidak terhubung ...</td>\n",
       "      <td>sering muncul ingat tidak hubung jaring orbit ...</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-28 00:14:40</td>\n",
       "      <td>Masih sering DC. Tiba2 g ada koneksi, lampu in...</td>\n",
       "      <td>1</td>\n",
       "      <td>Saifullah fil</td>\n",
       "      <td>masih sering dc tiba ada koneksi lampu indokat...</td>\n",
       "      <td>sering dc tiba koneksi lampu indokator merah e...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-24 13:44:07</td>\n",
       "      <td>Bapuk. Lemot. Padahal sudah di Taru dekat jend...</td>\n",
       "      <td>1</td>\n",
       "      <td>allan afriyadi</td>\n",
       "      <td>bapuk lemot padahal sudah di taru dekat jendel...</td>\n",
       "      <td>jelek lambat padahal taru dekat jendela lantai...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-18 21:58:35</td>\n",
       "      <td>Sering muncul tulisan \"tidak terhubung ke .......</td>\n",
       "      <td>3</td>\n",
       "      <td>Suryokusumo Risdika Rizki</td>\n",
       "      <td>sering muncul tulisan tidak terhubung ke nama ...</td>\n",
       "      <td>sering muncul tulis hubung nama wifi padahal j...</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-02 21:40:00</td>\n",
       "      <td>Sudah beli model yg harganya sampai 2 jutaan. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Anton Karnadi</td>\n",
       "      <td>sudah beli model yg harganya sampai jutaan awa...</td>\n",
       "      <td>beli model harga juta awal kencang tahun pakai...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>2023-02-06 16:52:51</td>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "      <td>Prinstony Bella</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>2023-05-01 18:30:41</td>\n",
       "      <td>Semngat</td>\n",
       "      <td>4</td>\n",
       "      <td>Agus Adekaputra</td>\n",
       "      <td>semngat</td>\n",
       "      <td>semngat</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>2023-01-18 22:03:06</td>\n",
       "      <td>üôèüôèüôèüôè</td>\n",
       "      <td>5</td>\n",
       "      <td>Meki Mote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>2023-04-02 18:06:26</td>\n",
       "      <td>üëçüëçüëçüëç</td>\n",
       "      <td>5</td>\n",
       "      <td>Bertus Soen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>2023-04-07 21:56:40</td>\n",
       "      <td>Bagus Bagus</td>\n",
       "      <td>5</td>\n",
       "      <td>Willyamsfrimaulana Willy</td>\n",
       "      <td>bagus bagus</td>\n",
       "      <td>bagus bagus</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3022 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       at                                            content  \\\n",
       "0     2023-09-21 14:31:30  Sering muncul peringatan 'anda tidak terhubung...   \n",
       "1     2023-09-28 00:14:40  Masih sering DC. Tiba2 g ada koneksi, lampu in...   \n",
       "2     2023-09-24 13:44:07  Bapuk. Lemot. Padahal sudah di Taru dekat jend...   \n",
       "3     2023-09-18 21:58:35  Sering muncul tulisan \"tidak terhubung ke .......   \n",
       "4     2023-10-02 21:40:00  Sudah beli model yg harganya sampai 2 jutaan. ...   \n",
       "...                   ...                                                ...   \n",
       "3017  2023-02-06 16:52:51                                               Good   \n",
       "3018  2023-05-01 18:30:41                                            Semngat   \n",
       "3019  2023-01-18 22:03:06                                               üôèüôèüôèüôè   \n",
       "3020  2023-04-02 18:06:26                                               üëçüëçüëçüëç   \n",
       "3021  2023-04-07 21:56:40                                        Bagus Bagus   \n",
       "\n",
       "      score                   userName  \\\n",
       "0         5                 Wilson Nts   \n",
       "1         1              Saifullah fil   \n",
       "2         1             allan afriyadi   \n",
       "3         3  Suryokusumo Risdika Rizki   \n",
       "4         3              Anton Karnadi   \n",
       "...     ...                        ...   \n",
       "3017      4            Prinstony Bella   \n",
       "3018      4            Agus Adekaputra   \n",
       "3019      5                  Meki Mote   \n",
       "3020      5                Bertus Soen   \n",
       "3021      5   Willyamsfrimaulana Willy   \n",
       "\n",
       "                                               contentp  \\\n",
       "0     sering muncul peringatan anda tidak terhubung ...   \n",
       "1     masih sering dc tiba ada koneksi lampu indokat...   \n",
       "2     bapuk lemot padahal sudah di taru dekat jendel...   \n",
       "3     sering muncul tulisan tidak terhubung ke nama ...   \n",
       "4     sudah beli model yg harganya sampai jutaan awa...   \n",
       "...                                                 ...   \n",
       "3017                                               good   \n",
       "3018                                            semngat   \n",
       "3019                                                NaN   \n",
       "3020                                                NaN   \n",
       "3021                                        bagus bagus   \n",
       "\n",
       "                                         contentp_clean  text_length  \n",
       "0     sering muncul ingat tidak hubung jaring orbit ...          238  \n",
       "1     sering dc tiba koneksi lampu indokator merah e...          226  \n",
       "2     jelek lambat padahal taru dekat jendela lantai...          269  \n",
       "3     sering muncul tulis hubung nama wifi padahal j...          240  \n",
       "4     beli model harga juta awal kencang tahun pakai...          147  \n",
       "...                                                 ...          ...  \n",
       "3017                                               good            4  \n",
       "3018                                            semngat            7  \n",
       "3019                                                NaN            0  \n",
       "3020                                                NaN            0  \n",
       "3021                                        bagus bagus           11  \n",
       "\n",
       "[3022 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_review_all.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "wRh8M2XxFJJ7",
    "outputId": "ca15163d-b097-4cee-e696-8c69b334b9ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentp_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sering muncul ingat tidak hubung jaring orbit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sering dc tiba koneksi lampu indokator merah e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jelek lambat padahal taru dekat jendela lantai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sering muncul tulis hubung nama wifi padahal j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beli model harga juta awal kencang tahun pakai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>lelettt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>oke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>semngat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>bagus bagus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         contentp_clean\n",
       "0     sering muncul ingat tidak hubung jaring orbit ...\n",
       "1     sering dc tiba koneksi lampu indokator merah e...\n",
       "2     jelek lambat padahal taru dekat jendela lantai...\n",
       "3     sering muncul tulis hubung nama wifi padahal j...\n",
       "4     beli model harga juta awal kencang tahun pakai...\n",
       "...                                                 ...\n",
       "3014                                            lelettt\n",
       "3016                                                oke\n",
       "3017                                               good\n",
       "3018                                            semngat\n",
       "3021                                        bagus bagus\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa = df[['contentp_clean']]\n",
    "dfa = dfa.dropna()\n",
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4NEeugdJT50",
    "outputId": "44ff1ac0-f1fd-4b2e-8fde-9148e9c3884e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alharidt\\Documents\\GitHub\\text-Analysis\\Pertemuan 6\\Week_Class_6.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alharidt/Documents/GitHub/text-Analysis/Pertemuan%206/Week_Class_6.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhelper\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alharidt/Documents/GitHub/text-Analysis/Pertemuan%206/Week_Class_6.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alharidt/Documents/GitHub/text-Analysis/Pertemuan%206/Week_Class_6.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\helper\\__init__.py:134\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m....  ......        ....  .. .                  ....         .\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m.... .......          .   ....                           ....       .        ..\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39m :8=+.,?$:.......................................  .... .............    ..,,=\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhelper\u001b[39;00m \u001b[39mimport\u001b[39;00m parser, unix \u001b[39mas\u001b[39;00m platform\n\u001b[0;32m    136\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2.5.0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    137\u001b[0m version \u001b[39m=\u001b[39m __version__\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\helper\\unix.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39matexit\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgrp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'grp'"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd #a library to make the data more structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: celery in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (5.0.5)\n",
      "Requirement already satisfied: pytz>dev in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (2023.3.post1)\n",
      "Requirement already satisfied: billiard<4.0,>=3.6.3.0 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (3.6.4.0)\n",
      "Requirement already satisfied: kombu<6.0,>=5.0.0 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (5.3.2)\n",
      "Requirement already satisfied: vine<6.0,>=5.0.0 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (5.0.0)\n",
      "Requirement already satisfied: click<8.0,>=7.0 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (7.1.2)\n",
      "Requirement already satisfied: click-didyoumean>=0.0.3 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (0.3.0)\n",
      "Requirement already satisfied: click-repl>=0.1.6 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from celery) (1.1.1)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from click-repl>=0.1.6->celery) (3.0.39)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from kombu<6.0,>=5.0.0->celery) (5.1.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\alharidt\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.1.6->celery) (0.2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: celery 5.0.5 has a non-standard dependency specifier pytz>dev. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install celery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsS-lBS9JUtC",
    "outputId": "223ec26f-948e-4f4a-8ce0-275e790c745b"
   },
   "outputs": [],
   "source": [
    "text = dfa['contentp_clean']\n",
    "text_list =  [i.split() for i in text]\n",
    "print(len(text_list))\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5eJd4ZIJalQ"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "#Create Bigram & Trigram Models\n",
    "from gensim.models import Phrases\n",
    "# Add bigrams and trigrams to docs,minimum count 10 means only that appear 10 times or more.\n",
    "bigram = Phrases(text_list, min_count=10)\n",
    "trigram = Phrases(bigram[text_list])\n",
    "for idx in range(len(text_list)):\n",
    "    for token in bigram[text_list[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            text_list[idx].append(token)\n",
    "    for token in trigram[text_list[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            text_list[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g4h877AJdfO",
    "outputId": "98ae4b69-f6ae-49f9-c87b-f500c18f8824"
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = corpora.Dictionary(text_list)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.2)\n",
    "#no_below (int, optional) ‚Äì Keep tokens which are contained in at least no_below documents.\n",
    "#no_above (float, optional) ‚Äì Keep tokens which are contained in no more than no_above documents (fraction of total corpus size, not an absolute number).\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caiN6kuSJsuC",
    "outputId": "78b0e4bb-299d-4242-91cf-63600b763fd2"
   },
   "outputs": [],
   "source": [
    "#https://radimrehurek.com/gensim/tut1.html\n",
    "#build corpus\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in text_list]\n",
    "#The function doc2bow converts document (a list of words) into the bag-of-words format\n",
    "'''The function doc2bow() simply counts the number of occurrences of each distinct word,\n",
    "converts the word to its integer word id and returns the result as a sparse vector.\n",
    "The sparse vector [(0, 1), (1, 1)] therefore reads: in the document ‚ÄúHuman computer interaction‚Äù,\n",
    "the words computer (id 0) and human (id 1) appear once;\n",
    "the other ten dictionary words appear (implicitly) zero times.'''\n",
    "print(len(doc_term_matrix))\n",
    "print(doc_term_matrix[100])\n",
    "tfidf = models.TfidfModel(doc_term_matrix) #build TF-IDF model\n",
    "corpus_tfidf = tfidf[doc_term_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXBRf0boJ3nH"
   },
   "source": [
    "## Coherence Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AyDMZYpJxmN"
   },
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "#function to compute coherence values\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, iterations=100)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "tLpOkLWaJ6qQ",
    "outputId": "fca1f5dd-6d84-48a7-9e8c-3b0ced02411b"
   },
   "outputs": [],
   "source": [
    "start=1\n",
    "limit=21\n",
    "step=1\n",
    "model_list, coherence_values = compute_coherence_values(dictionary, corpus=corpus_tfidf,\n",
    "                                                        texts=text_list, start=start, limit=limit, step=step)\n",
    "#show graphs\n",
    "import matplotlib.pyplot as plt\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uymbKZzCKe0x",
    "outputId": "2d26af19-4e52-42d9-dbbc-2e58038513be"
   },
   "outputs": [],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQM1COw7Kk33",
    "outputId": "125ea24e-eea1-4bfa-d0b8-379151efa510"
   },
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-DGA6dfKpEd",
    "outputId": "4083509d-5d61-42ec-82c1-415bcfaa7c3a"
   },
   "outputs": [],
   "source": [
    "model = LdaModel(corpus=corpus_tfidf, id2word=dictionary, num_topics=3) #num topic menyesuaikan hasil dari coherence value paling tinggi\n",
    "for idx, topic in model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zKooe3LKu23",
    "outputId": "7d77a493-4cb7-4064-e8f0-7bb7c2548c18"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "top_words_per_topic = []\n",
    "for t in range(model.num_topics):\n",
    "    top_words_per_topic.extend([(t, ) + x for x in model.show_topic(t, topn = 10)])\n",
    "#pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word', 'P']).to_csv(\"top_words.csv\")\n",
    "df = pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word','P']).to_csv(\"top_words2.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWjCC2-ULy6s",
    "outputId": "01fdbaaf-e458-4669-e413-90e306757a57"
   },
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90oJVyC-MKp-",
    "outputId": "561e35aa-9360-4ed7-cecc-e21be382755f"
   },
   "outputs": [],
   "source": [
    "corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eOkCk0f9NJ6c",
    "outputId": "64f8d9ce-3925-4545-850d-40f2e4a81a4c"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xZFooJZNSvN",
    "outputId": "202279c3-26c8-4480-d5ae-84038f32d9d7"
   },
   "outputs": [],
   "source": [
    "!pip install pyLDAvis==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPGfW-KuLFxS",
    "outputId": "9e308318-3c39-4160-ce4c-36f59301c324"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim;pyLDAvis.enable_notebook()\n",
    "data = pyLDAvis.gensim.prepare(model, corpus_tfidf, dictionary)\n",
    "print(data)\n",
    "pyLDAvis.save_html(data, 'lda-gensim.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feDJnU7IVWbu"
   },
   "outputs": [],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4YttkH5Zgyp"
   },
   "source": [
    "## Mapping Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp93-H4jWAg4"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "texts = []\n",
    "for i in dfa['contentp_clean']:\n",
    "  tokens = tokenizer.tokenize(i)\n",
    "  texts.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jEMYjMslTRTJ",
    "outputId": "6a7f3a79-214a-4528-bf4c-9e1edf10e751"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel.load('model')\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = ldamodel.id2word\n",
    "\n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=texts):\n",
    "  # Init output\n",
    "  sent_topics_df = pd.DataFrame()\n",
    "\n",
    "  # Get main topic in each document\n",
    "  for i, row_list in enumerate(ldamodel[corpus]):\n",
    "    row = row_list[0] if ldamodel.per_word_topics else row_list\n",
    "    print(row)\n",
    "    row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "    # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "    for j, (topic_num, prop_topic) in enumerate(row):\n",
    "      if j == 0:\n",
    "        wp = ldamodel.show_topic(topic_num)\n",
    "        topic_keywords = \", \".join([word for word, prop in wp])\n",
    "        sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "      else:\n",
    "        break\n",
    "  sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "  # Add original text to the end of the output\n",
    "  contents = pd.Series(texts)\n",
    "  sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "  return(sent_topics_df)\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=model, corpus=corpus, texts=texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "g_zVDcwBXccF",
    "outputId": "a0151d0b-385c-4d05-d217-2f31bc1d376c"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic['contentp_clean'] = df_dominant_topic['Text'].apply(' '.join)\n",
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r02AztpKX3_L"
   },
   "outputs": [],
   "source": [
    "topic_mapping = {\n",
    "    0: \"Harga Mahal\",\n",
    "    1: \"Aplikasi Error\",\n",
    "    2: \"Pelayanan\",\n",
    "    # Add mappings for all your topics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqIoLopkYImT"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic['Topic'] = df_dominant_topic['Dominant_Topic'].map(topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muzK97yJYPRF",
    "outputId": "be051227-5a55-4c90-8679-700fe745c19d"
   },
   "outputs": [],
   "source": [
    "list(df_dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Auk8e35rYfRd",
    "outputId": "b6d97950-6f6f-4433-999c-6b7c23cadfea"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic = df_dominant_topic[[\n",
    " 'Dominant_Topic',\n",
    " 'Topic_Perc_Contrib',\n",
    " 'Keywords',\n",
    " 'contentp_clean',\n",
    " 'Topic']]\n",
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dW0QuwC0Y9Et"
   },
   "outputs": [],
   "source": [
    "topic_percentages = df_dominant_topic['Topic'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "zlpCi6MbZBvY",
    "outputId": "75724ee9-ac40-4b11-e94f-661ae3b8df53"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topic_percentages.plot(kind='bar')\n",
    "plt.xlabel('Dominant Topic')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of Topics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RWmMzGZKZOaH",
    "outputId": "11851798-b897-4d26-d24c-4685b52bd3cb"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "unique_topics = df_dominant_topic['Topic'].unique()\n",
    "\n",
    "for topic in unique_topics:\n",
    "    text = ' '.join(df_dominant_topic[df_dominant_topic['Topic'] == topic]['contentp_clean'])\n",
    "    wordcloud = WordCloud(width=800, height=400).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for Topic {topic}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpzgjclcyWJk/HvFvqXxra",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
